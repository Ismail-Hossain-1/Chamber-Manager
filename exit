[33mcommit 47010e78636a42bf9c664cdd50571c44bb3643bb[m[33m ([m[1;36mHEAD -> [m[1;32mmain[m[33m)[m
Author: Ismail-Hossain-1 <107604527+Ismail-Hossain-1@users.noreply.github.com>
Date:   Sat Jul 6 23:31:36 2024 +0600

    Initial

[1mdiff --git a/.gitignore b/.gitignore[m
[1mnew file mode 100644[m
[1mindex 0000000..4c49bd7[m
[1m--- /dev/null[m
[1m+++ b/.gitignore[m
[36m@@ -0,0 +1 @@[m
[32m+[m[32m.env[m
[1mdiff --git a/__pycache__/app.cpython-312.pyc b/__pycache__/app.cpython-312.pyc[m
[1mnew file mode 100644[m
[1mindex 0000000..cd0fb1c[m
Binary files /dev/null and b/__pycache__/app.cpython-312.pyc differ
[1mdiff --git a/app.py b/app.py[m
[1mnew file mode 100644[m
[1mindex 0000000..94f5558[m
[1m--- /dev/null[m
[1m+++ b/app.py[m
[36m@@ -0,0 +1,56 @@[m
[32m+[m[32mfrom flask import Flask, request, jsonify, Response, g, render_template[m
[32m+[m[32mfrom dotenv import load_dotenv[m
[32m+[m[32mimport google.generativeai as genai[m
[32m+[m[32mimport marko[m
[32m+[m[32mimport os[m
[32m+[m
[32m+[m[32mload_dotenv()[m
[32m+[m
[32m+[m
[32m+[m[32mgenai.configure(api_key=os.getenv('GenAPI_KEY'))[m
[32m+[m[32mapp = Flask(__name__)[m
[32m+[m
[32m+[m
[32m+[m
[32m+[m
[32m+[m[32m@app.route('/')[m
[32m+[m[32mdef hello():[m
[32m+[m[32m    return 'Hello World'[m
[32m+[m[32mdef getWearher():[m
[32m+[m[32m           """ To get the current weather """[m
[32m+[m[32m           return '34 degree'[m
[32m+[m[41m [m
[32m+[m
[32m+[m[32mmodel= genai.GenerativeModel(model_name='gemini-1.5-flash')[m
[32m+[m[32mchat_history=[][m[41m      [m
[32m+[m
[32m+[m[32m@app.route('/api/chat' , methods=['POST'])[m
[32m+[m[32mdef ChatController():[m
[32m+[m[41m    [m
[32m+[m[41m    [m
[32m+[m
[32m+[m[32m    try:[m
[32m+[m[32m        prompt = request.get_json()['prompt'][m
[32m+[m[41m        [m
[32m+[m[32m        chat_history.append({[m
[32m+[m[32m            "role": "user",[m
[32m+[m[32m            "parts": [[m
[32m+[m[32m                {"text": prompt},[m
[32m+[m[32m                {"text": "You are an AI assistant of MyChamber application"},[m
[32m+[m[32m                {"text": "Mychamber is a application for doctor to manage their chamber"},[m
[32m+[m[32m                {"text": "currently you are serving a doctor called Ismail and his other informations are ang:24 "}[m
[32m+[m[32m            ][m
[32m+[m[32m        })[m
[32m+[m[41m        [m
[32m+[m[32m        chat= model.start_chat(history=chat_history, enable_automatic_function_calling=True)[m
[32m+[m
[32m+[m[32m        response= chat.send_message(prompt)[m
[32m+[m[32m        #response.resolve()[m
[32m+[m[32m        return jsonify({[m
[32m+[m[32m            "response": response.text[m
[32m+[m[32m            })[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        return jsonify({'error': str(e)})[m
[32m+[m
[32m+[m[32mif __name__ == '__main__':[m
[32m+[m[32m    app.run(debug=True, port=5001)[m
\ No newline at end of file[m
[1mdiff --git a/main.py b/main.py[m
[1mnew file mode 100644[m
[1mindex 0000000..6ca804f[m
[1m--- /dev/null[m
[1m+++ b/main.py[m
[36m@@ -0,0 +1,55 @@[m
[32m+[m[32mfrom flask import Flask, request, jsonify, Response, g, render_template[m
[32m+[m[32mfrom dotenv import load_dotenv[m
[32m+[m[32mimport google.generativeai as genai[m
[32m+[m[32mimport marko[m
[32m+[m[32mimport os[m
[32m+[m
[32m+[m[32mload_dotenv()[m
[32m+[m
[32m+[m
[32m+[m[32mgenai.configure(api_key=os.getenv('GenAPI_KEY'))[m
[32m+[m[32mapp = Flask(__name__)[m
[32m+[m
[32m+[m
[32m+[m[32mdef get_weather(request:str):[m
[32m+[m[32m    """returns weather information"""[m
[32m+[m[32m    return {"weather":"34 degree"}[m
[32m+[m
[32m+[m[32mdef subtract(a: float, b: float):[m
[32m+[m[32m    """returns a - b."""[m
[32m+[m[32m    return a - b[m
[32m+[m
[32m+[m[32mdef multiply(a: float, b: float):[m
[32m+[m[32m    """returns a * b."""[m
[32m+[m[32m    return (a * b) - 8[m[41m [m
[32m+[m
[32m+[m[32mdef divide(a: float, b: float):[m
[32m+[m[32m    """returns a / b."""[m
[32m+[m[32m    return a / b[m
[32m+[m
[32m+[m[32m# Initialize generative model[m
[32m+[m[32mmodel = genai.GenerativeModel([m
[32m+[m[32m    model_name="gemini-1.5-flash",[m
[32m+[m[32m    tools=[get_weather,subtract, multiply, divide][m
[32m+[m[32m)[m
[32m+[m[32mchat = model.start_chat(enable_automatic_function_calling=True)[m
[32m+[m
[32m+[m[32m# Route for interacting with the generative model[m
[32m+[m[32m@app.route('/ask', methods=['POST'])[m
[32m+[m[32mdef ask_question():[m
[32m+[m[32m    data = request.get_json()[m
[32m+[m[32m    question = data['question'][m
[32m+[m[32m    print(question)[m
[32m+[m
[32m+[m[32m    try:[m
[32m+[m[32m        # Send message to the generative model chat[m
[32m+[m[32m        response = chat.send_message(question)[m
[32m+[m[32m        text = response.text[m
[32m+[m
[32m+[m[32m        return jsonify({"response": text})[m
[32m+[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        return jsonify({"error": str(e)}), 500[m
[32m+[m
[32m+[m[32mif __name__ == '__main__':[m
[32m+[m[32m    app.run(debug=True, port=8080)[m
\ No newline at end of file[m
[1mdiff --git a/requirements.txt b/requirements.txt[m
[1mnew file mode 100644[m
[1mindex 0000000..1900ac2[m
Binary files /dev/null and b/requirements.txt differ
